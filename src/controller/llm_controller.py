# controller/llm_controller.py

from clients.llm.llm_client import LLMClient
from clients.logging.logger import logger
import time
import sys

class LLMController:
    def __init__(self, config):
        self.llm_client = LLMClient()
        self.retry_time = config.retry_config.retry_max_time
        self.retry_interval = config.retry_config.retry_interval_time

    def fix_code_with_llm(self, prompt):
        """éæµå¼ä¿®å¤ä»£ç ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        for attempt in range(self.retry_time):
            try:
                result = self.llm_client.fix_code(prompt)
                logger.info(f"LLMå“åº”æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(result)}")
                return result
            except Exception as e:
                logger.warning(f"LLMè¯·æ±‚å¤±è´¥: {e}, retry {attempt+1}/{self.retry_time}")
                time.sleep(self.retry_interval)
        logger.error("LLMä¿®å¤è¯·æ±‚å¤šæ¬¡å¤±è´¥ï¼Œç»ˆæ­¢ã€‚")
        return ""

    def fix_code_with_llm_stream(self, prompt):
        """æµå¼ä¿®å¤ä»£ç ï¼ŒåŠ¨æ€æ˜¾ç¤ºåˆ†æè¿›åº¦"""
        try:
            logger.info("å¼€å§‹æµå¼LLMä¿®å¤...")
            print(f"ğŸ¤– AIåˆ†æå¼€å§‹...", flush=True)
            
            full_response = ""
            line_count = 0
            
            for chunk in self.llm_client.fix_code_stream(prompt):
                full_response += chunk
                
                # è®¡ç®—å½“å‰è¡Œæ•°ï¼ˆé€šè¿‡æ¢è¡Œç¬¦è®¡ç®—ï¼‰
                new_line_count = full_response.count('\n')
                if new_line_count > line_count:
                    line_count = new_line_count
                    # åŠ¨æ€æ›´æ–°åˆ†æè¿›åº¦
                    print(f"\rğŸ¤– æ­£åœ¨åˆ†æç¬¬ {line_count} è¡Œä»£ç ...", end="", flush=True)
                
                sys.stdout.flush()
            
            # å®Œæˆåæ¢è¡Œå¹¶æ˜¾ç¤ºæœ€ç»ˆç»“æœ
            print(f"\nğŸ¤– AIåˆ†æå®Œæˆï¼Œå…±åˆ†æ {line_count} è¡Œï¼Œå“åº”é•¿åº¦: {len(full_response)}", flush=True)
            logger.info(f"æµå¼LLMå“åº”æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(full_response)}")
            return full_response
            
        except Exception as e:
            error_msg = f"æµå¼LLMè¯·æ±‚å¤±è´¥: {e}"
            logger.error(error_msg)
            print(f"\nâŒ {error_msg}", flush=True)
            return ""

    def analyze_pipeline_logs(self, logs):
        """åˆ†æPipelineæ—¥å¿—ï¼Œä½¿ç”¨åŠ¨æ€è¿›åº¦æ˜¾ç¤º"""
        try:
            logger.info("å¼€å§‹åˆ†æPipelineæ—¥å¿—...")
            print(f"ğŸ” å¼€å§‹åˆ†æPipelineæ—¥å¿—...", flush=True)
            
            full_response = ""
            line_count = 0
            
            for chunk in self.llm_client.analyze_pipeline_logs(logs):
                full_response += chunk
                
                # è®¡ç®—å½“å‰è¡Œæ•°
                new_line_count = full_response.count('\n')
                if new_line_count > line_count:
                    line_count = new_line_count
                    print(f"\rğŸ” æ­£åœ¨åˆ†æç¬¬ {line_count} è¡Œæ—¥å¿—...", end="", flush=True)
                
                sys.stdout.flush()
            
            print(f"\nâœ… æ—¥å¿—åˆ†æå®Œæˆï¼Œå…±åˆ†æ {line_count} è¡Œ", flush=True)
            logger.info(f"Pipelineæ—¥å¿—åˆ†æå®Œæˆï¼Œå“åº”é•¿åº¦: {len(full_response)}")
            return full_response
            
        except Exception as e:
            error_msg = f"Pipelineæ—¥å¿—åˆ†æå¤±è´¥: {e}"
            logger.error(error_msg)
            print(f"\nâŒ {error_msg}", flush=True)
            return ""